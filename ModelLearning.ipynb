{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "import cPickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return cPickle.load(f)\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/' + name + '.pkl', 'wb') as f:\n",
    "        cPickle.dump(obj, f)#,  marshal.version)#, marshal.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langdetect import detect\\n\\nclass FeatureGenerator:\\n    \\n    def __init__(self, lm):\\n        self.lm = lm\\n    \\n    def generate_features(self, query):\\n        x = []\\n        words = re.findall(ur\"(?u)\\\\w+\", query)\\n        x.append(len(words))# \\xd0\\xba\\xd0\\xbe\\xd0\\xbb\\xd0\\xb8\\xd1\\x87\\xd0\\xb5\\xd1\\x81\\xd1\\x82\\xd0\\xb2\\xd0\\xbe \\xd1\\x81\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2\\n        x.append(len(query))# \\xd0\\xba\\xd0\\xbe\\xd0\\xbb\\xd0\\xb8\\xd1\\x87\\xd0\\xb5\\xd1\\x81\\xd1\\x82\\xd0\\xb2\\xd0\\xbe \\xd1\\x81\\xd0\\xb8\\xd0\\xbc\\xd0\\xb2\\xd0\\xbe\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2\\n        x.append(self.lm.get_prob(words)) # \\xd0\\xb2\\xd0\\xb5\\xd1\\x80\\xd0\\xbe\\xd1\\x8f\\xd1\\x82\\xd0\\xbd\\xd0\\xbe\\xd1\\x81\\xd1\\x82\\xd1\\x8c \\xd1\\x82\\xd0\\xb0\\xd0\\xba\\xd0\\xbe\\xd0\\xb3\\xd0\\xbe \\xd0\\xb7\\xd0\\xb0\\xd0\\xbf\\xd1\\x80\\xd0\\xbe\\xd1\\x81\\xd0\\xb0\\n        max_prob = -1.\\n        min_prob = 2.\\n        \\n        count_of_words_in_dict = 0\\n        for word in words:\\n            prob = self.lm.get_word_prob(word)\\n            if prob > max_prob:\\n                max_prob = prob\\n            if prob < min_prob:\\n                min_prob = prob\\n                \\n            if self.lm.dict.has_key(word):\\n                count_of_words_in_dict += 1\\n                \\n        x.append(max_prob) # \\xd0\\xbc\\xd0\\xb0\\xd0\\xba\\xd1\\x81\\xd0\\xb8\\xd0\\xbc\\xd0\\xb0\\xd0\\xbb\\xd1\\x8c\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xb5\\xd1\\x80\\xd0\\xbe\\xd1\\x8f\\xd1\\x82\\xd0\\xbd\\xd0\\xbe\\xd1\\x81\\xd1\\x82\\xd1\\x8c \\xd1\\x81\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\n        x.append(min_prob) # \\xd0\\xbc\\xd0\\xb8\\xd0\\xbd\\xd0\\xb8\\xd0\\xbc\\xd0\\xb0\\xd0\\xbb\\xd1\\x8c\\xd0\\xbd\\xd0\\xb0\\xd1\\x8f \\xd0\\xb2\\xd0\\xb5\\xd1\\x80\\xd0\\xbe\\xd1\\x8f\\xd1\\x82\\xd0\\xbd\\xd0\\xbe\\xd1\\x81\\xd1\\x82\\xd1\\x8c \\xd1\\x81\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\n        x.append(len(words)-count_of_words_in_dict) # \\xd1\\x81\\xd0\\xba\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c\\xd0\\xba\\xd0\\xbe \\xd1\\x81\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2 \\xd0\\xbd\\xd0\\xb5\\xd1\\x82 \\xd0\\xb2 \\xd1\\x81\\xd0\\xbb\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x80\\xd0\\xb5\\n        \\n        if u\",\" in query or             u\".\" in query or             u\"\\'\" in query or             u\";\" in query or             u\"]\" in query or             u\"[\" in query or             u\"~\" in query:\\n            x.append(1) # \\xd0\\xb5\\xd1\\x81\\xd1\\x82\\xd1\\x8c \\xd0\\xbb\\xd0\\xb8 \"\\xd0\\xbf\\xd0\\xbb\\xd0\\xbe\\xd1\\x85\\xd0\\xb8\\xd0\\xb5\" \\xd1\\x81\\xd0\\xb8\\xd0\\xbc\\xd0\\xb2\\xd0\\xbe\\xd0\\xbb\\xd1\\x8b \\xd0\\xb2 \\xd0\\xb7\\xd0\\xb0\\xd0\\xbf\\xd1\\x80\\xd0\\xbe\\xd1\\x81\\xd0\\xb5 \\n        else:\\n            x.append(0)\\n\\n        try:\\n            lang = detect(query)\\n            lang = 1 if lang == \\'en\\' else 0\\n        except Exception:\\n            lang = 0\\n            \\n        x.append(lang) # \\xd1\\x8f\\xd0\\xb7\\xd1\\x8b\\xd0\\xba\\n\\n        \\n        return x\\n        \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Engine.Classifier.FeatureGenerator import FeatureGenerator\n",
    "\"\"\"\n",
    "from langdetect import detect\n",
    "\n",
    "class FeatureGenerator:\n",
    "    \n",
    "    def __init__(self, lm):\n",
    "        self.lm = lm\n",
    "    \n",
    "    def generate_features(self, query):\n",
    "        x = []\n",
    "        words = re.findall(ur\"(?u)\\w+\", query)\n",
    "        x.append(len(words))# количество слов\n",
    "        x.append(len(query))# количество символов\n",
    "        x.append(self.lm.get_prob(words)) # вероятность такого запроса\n",
    "        max_prob = -1.\n",
    "        min_prob = 2.\n",
    "        \n",
    "        count_of_words_in_dict = 0\n",
    "        for word in words:\n",
    "            prob = self.lm.get_word_prob(word)\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                \n",
    "            if self.lm.dict.has_key(word):\n",
    "                count_of_words_in_dict += 1\n",
    "                \n",
    "        x.append(max_prob) # максимальная вероятность слова\n",
    "        x.append(min_prob) # минимальная вероятность слова\n",
    "        x.append(len(words)-count_of_words_in_dict) # сколько слов нет в словаре\n",
    "        \n",
    "        if u\",\" in query or \\\n",
    "            u\".\" in query or \\\n",
    "            u\"'\" in query or \\\n",
    "            u\";\" in query or \\\n",
    "            u\"]\" in query or \\\n",
    "            u\"[\" in query or \\\n",
    "            u\"~\" in query:\n",
    "            x.append(1) # есть ли \"плохие\" символы в запросе \n",
    "        else:\n",
    "            x.append(0)\n",
    "\n",
    "        try:\n",
    "            lang = detect(query)\n",
    "            lang = 1 if lang == 'en' else 0\n",
    "        except Exception:\n",
    "            lang = 0\n",
    "            \n",
    "        x.append(lang) # язык\n",
    "\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = load_obj(\"LanguageModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/right_queries.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "queries = content[0].split(\"<br><br>\")\n",
    "\n",
    "correct_q = queries[:1000]\n",
    "\n",
    "bad_q = queries[1002:]\n",
    "need_fix = bad_q[:1000]\n",
    "need_split = bad_q[1002:2002]\n",
    "need_join = bad_q[2004:3004]\n",
    "\n",
    "bad_q = need_fix\n",
    "bad_q.extend(need_split)\n",
    "bad_q.extend(need_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_formated_text(text):\n",
    "    textFormatter = TextFormatter(text)\n",
    "    words = textFormatter.get_query_list()\n",
    "    query = textFormatter.text\n",
    "    \n",
    "    return query, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from Engine.TextFormatter import TextFormatter\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "fg = FeatureGenerator(lm)\n",
    "i=0\n",
    "with open(\"data/queries_all.txt\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for line in content:\n",
    "    if random() < 0.2:\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    if i > 50000:\n",
    "        break\n",
    "        \n",
    "    #line = line.decode(\"utf-8\")\n",
    "    #line = line.lower()\n",
    "    #line = line[:-1]\n",
    "    queries = line.split('\\t')\n",
    "    \n",
    "    if len(queries) == 2:\n",
    "        y.append(0)\n",
    "        query, words = get_formated_text(queries[0])\n",
    "        X.append(fg.generate_features(query, words))\n",
    "        \n",
    "        y.append(1)\n",
    "        query, words = get_formated_text(queries[1])\n",
    "        X.append(fg.generate_features(query, words))\n",
    "        \n",
    "    else:\n",
    "        y.append(1)\n",
    "        query, words = get_formated_text(queries[0])\n",
    "        X.append(fg.generate_features(query, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for q in correct_q:\n",
    "    y.append(1)\n",
    "    query, words = get_formated_text(q)\n",
    "    X.append(fg.generate_features(query, words))\n",
    "    \n",
    "    \n",
    "for q in bad_q:\n",
    "    y.append(0)\n",
    "    query, words = get_formated_text(q)\n",
    "    X.append(fg.generate_features(query, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833910609076\n",
      "0.969942487649\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "acc = []\n",
    "kf = KFold(len(y), n_folds=4, shuffle=True)\n",
    "for train_index, test_index in kf:\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    \n",
    "    gb = GradientBoostingClassifier(n_estimators=200, max_depth=5, loss='exponential')#, max_features=5, learning_rate=0.04)\n",
    "    gb.fit(X_train, y_train)\n",
    "    \n",
    "    y_predicted = gb.predict(X_test)\n",
    "    f1.append(f1_score(y_test, y_predicted, pos_label=0))\n",
    "    acc.append(accuracy_score(y_test, y_predicted))\n",
    "    \n",
    "print sum(f1)/len(f1)\n",
    "print sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_obj(gb, \"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99634551495016621"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=20, max_depth=None, loss='exponential')\n",
    "gb.fit(X, y)\n",
    "y_pred = gb.predict(X)\n",
    "f1_score(y, y_pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_obj(gb, \"classifier_input\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
