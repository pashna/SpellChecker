{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect\n",
    "import cPickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return cPickle.load(f)\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/' + name + '.pkl', 'wb') as f:\n",
    "        cPickle.dump(obj, f)#,  marshal.version)#, marshal.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "class FeatureGenerator:\n",
    "    \n",
    "    def __init__(self, lm):\n",
    "        self.lm = lm\n",
    "    \n",
    "    def generate_features(self, query):\n",
    "        x = []\n",
    "        words = re.findall(ur\"(?u)\\w+\", query)\n",
    "        x.append(len(words))# количество слов\n",
    "        x.append(len(query))# количество символов\n",
    "        x.append(self.lm.get_prob(words)) # вероятность такого запроса\n",
    "        max_prob = -1.\n",
    "        min_prob = 2.\n",
    "        \n",
    "        count_of_words_in_dict = 0\n",
    "        for word in words:\n",
    "            prob = self.lm.get_word_prob(word)\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                \n",
    "            if self.lm.dict.has_key(word):\n",
    "                count_of_words_in_dict += 1\n",
    "                \n",
    "        x.append(max_prob) # максимальная вероятность слова\n",
    "        x.append(min_prob) # минимальная вероятность слова\n",
    "        x.append(len(words)-count_of_words_in_dict) # сколько слов нет в словаре\n",
    "        \n",
    "        if u\",\" in query or \\\n",
    "            u\".\" in query or \\\n",
    "            u\"'\" in query or \\\n",
    "            u\";\" in query or \\\n",
    "            u\"]\" in query or \\\n",
    "            u\"[\" in query or \\\n",
    "            u\"~\" in query:\n",
    "            x.append(1) # есть ли \"плохие\" символы в запросе \n",
    "        else:\n",
    "            x.append(0)\n",
    "        \n",
    "        try:\n",
    "            lang = detect(query)\n",
    "            lang = 1 if lang == 'en' else 0\n",
    "        except Exception:\n",
    "            lang = 0\n",
    "            \n",
    "        x.append(lang) # язык\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = load_obj(\"LanguageModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/right_queries.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "queries = content[0].split(\"<br><br>\")\n",
    "\n",
    "correct_q = queries[:1000]\n",
    "\n",
    "bad_q = queries[1002:]\n",
    "need_fix = bad_q[:1000]\n",
    "need_split = bad_q[1002:2002]\n",
    "need_join = bad_q[2004:3004]\n",
    "\n",
    "bad_q = need_fix\n",
    "bad_q.extend(need_split)\n",
    "bad_q.extend(need_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "fg = FeatureGenerator(lm)\n",
    "i=0\n",
    "with open(\"data/queries_all.txt\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for line in content:\n",
    "    if random() < 0.2:\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    if i > 20000:\n",
    "        break\n",
    "        \n",
    "    line = line.decode(\"utf-8\")\n",
    "    line = line.lower()\n",
    "    line = line[:-1]\n",
    "    queries = line.split('\\t')\n",
    "\n",
    "    if len(queries) == 2:\n",
    "        y.append(0)\n",
    "        X.append(fg.generate_features(queries[0]))\n",
    "        \n",
    "        y.append(1)\n",
    "        X.append(fg.generate_features(queries[1]))\n",
    "        \n",
    "    else:\n",
    "        y.append(1)\n",
    "        X.append(fg.generate_features(queries[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for q in correct_q:\n",
    "    q = q.decode(\"utf-8\")\n",
    "    q = q.lower()\n",
    "    y.append(1)\n",
    "    X.append(fg.generate_features(q))\n",
    "    \n",
    "for q in bad_q:\n",
    "    q = q.decode(\"utf-8\")\n",
    "    q = q.lower()\n",
    "    y.append(0)\n",
    "    X.append(fg.generate_features(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890758156029\n",
      "0.83475\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "acc = []\n",
    "kf = KFold(len(y), n_folds=4, shuffle=True)\n",
    "for train_index, test_index in kf:\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    \n",
    "    gb = GradientBoostingClassifier(n_estimators=200, max_depth=None, loss='exponential')#, max_features=5, learning_rate=0.04)\n",
    "    gb.fit(X_train, y_train)\n",
    "    \n",
    "    y_predicted = gb.predict(X_test)\n",
    "    f1.append(f1_score(y_test, y_predicted, pos_label=0))\n",
    "    acc.append(accuracy_score(y_test, y_predicted))\n",
    "    \n",
    "print sum(f1)/len(f1)\n",
    "print sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99634551495016621"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=20, max_depth=None, loss='exponential')\n",
    "gb.fit(X, y)\n",
    "y_pred = gb.predict(X)\n",
    "f1_score(y, y_pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_obj(gb, \"classifier_input\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
